{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project - Option 1\n",
    "\n",
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/conda/miniconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (2023.12.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (12.4.127)\n",
      "Requirement already satisfied: triton==3.1.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (3.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/miniconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/miniconda3/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline,Transformer\n",
    "from pyspark.ml.feature import Imputer,StandardScaler,StringIndexer,OneHotEncoder, VectorAssembler\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.window import Window\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from pyspark.sql.functions import udf, col, when\n",
    "from pyspark.sql.types import ArrayType, FloatType, StringType, IntegerType\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import FloatType\n",
    "import warnings\n",
    "import torch\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from itertools import product\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/14 18:23:48 INFO SparkEnv: Registering MapOutputTracker\n",
      "24/11/14 18:23:48 INFO SparkEnv: Registering BlockManagerMaster\n",
      "24/11/14 18:23:48 INFO SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "24/11/14 18:23:48 INFO SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "appName = \"Big Data Analytics\"\n",
    "master = \"yarn\"\n",
    "\n",
    "# Create Configuration object for Spark.\n",
    "conf = pyspark.SparkConf()\\\n",
    "   .setAppName(appName)\\\n",
    "    .setMaster(master)\n",
    "\n",
    "spark = SparkSession.builder.config(conf = conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://jmodh_systems/Data/female_players_16.csv...\n",
      "Copying gs://jmodh_systems/Data/female_players_17.csv...                        \n",
      "Copying gs://jmodh_systems/Data/female_players_18.csv...                        \n",
      "Copying gs://jmodh_systems/Data/female_players_19.csv...                        \n",
      "/ [4 files][682.2 KiB/682.2 KiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying gs://jmodh_systems/Data/female_players_20.csv...\n",
      "Copying gs://jmodh_systems/Data/female_players_21.csv...                        \n",
      "Copying gs://jmodh_systems/Data/female_players_22.csv...                        \n",
      "Copying gs://jmodh_systems/Data/players_15.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_16.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_17.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_18.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_19.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_20.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_21.csv...                               \n",
      "Copying gs://jmodh_systems/Data/players_22.csv...                               \n",
      "/ [15 files][ 95.4 MiB/ 95.4 MiB]                                               \n",
      "Operation completed over 15 objects/95.4 MiB.                                    \n",
      "put: `/user/spark/female_players_16.csv': File exists\n",
      "put: `/user/spark/female_players_17.csv': File exists\n",
      "put: `/user/spark/female_players_18.csv': File exists\n",
      "put: `/user/spark/female_players_19.csv': File exists\n",
      "put: `/user/spark/female_players_20.csv': File exists\n",
      "put: `/user/spark/female_players_21.csv': File exists\n",
      "put: `/user/spark/female_players_22.csv': File exists\n",
      "put: `/user/spark/players_15.csv': File exists\n",
      "put: `/user/spark/players_16.csv': File exists\n",
      "put: `/user/spark/players_17.csv': File exists\n",
      "put: `/user/spark/players_18.csv': File exists\n",
      "put: `/user/spark/players_19.csv': File exists\n",
      "put: `/user/spark/players_20.csv': File exists\n",
      "put: `/user/spark/players_21.csv': File exists\n",
      "put: `/user/spark/players_22.csv': File exists\n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r gs://jmodh_systems/Data /tmp/\n",
    "!hadoop fs -put /tmp/Data/* /user/spark/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_male = spark.read.csv('/user/spark/players_15.csv', header = True)\n",
    "combined_df = df_male.withColumn(\"year\", lit(2015))\n",
    "# combined_df = combined_df.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *combined_df.columns)\n",
    "combined_df = combined_df.withColumn(\"gender\", lit(\"Male\"))\n",
    "folder_path = \"/user/spark/\"\n",
    "file_list = spark.sparkContext._jvm.org.apache.hadoop.fs.FileSystem.get(\n",
    "    spark.sparkContext._jsc.hadoopConfiguration()).listStatus(\n",
    "    spark.sparkContext._jvm.org.apache.hadoop.fs.Path(folder_path))\n",
    "\n",
    "for file_status in file_list:\n",
    "    file_name = file_status.getPath().getName()\n",
    "    if file_name == \"players_15.csv\":\n",
    "        continue\n",
    "    year = \"20\" + file_name[-6:-4]\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    df_read = spark.read.csv(file_path, header = True)\n",
    "    df_read = df_read.withColumn(\"year\", lit(int(year)))\n",
    "    # df_read = df_read.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *df_read.columns)\n",
    "    if \"female\" in file_name:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Female\"))\n",
    "    else:\n",
    "        df_read = df_read.withColumn(\"gender\", lit(\"Male\"))\n",
    "    combined_df = combined_df.union(df_read)\n",
    "combined_df = combined_df.withColumn(\"record_id\", monotonically_increasing_id()).select(\"record_id\", *combined_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_from_spark():\n",
    "    df = combined_df.filter(combined_df[\"gender\"] == \"Male\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_clubs_with_contracts_ending(X, Y, Z):\n",
    "    df = read_from_spark()\n",
    "    df_filtered = df.filter(col(\"year\") == X)\n",
    "    df_expiring = df_filtered.filter(col(\"club_contract_valid_until\").cast(\"int\") >= Z)\n",
    "    result = df_expiring.groupBy(\"club_name\") \\\n",
    "        .count() \\\n",
    "        .orderBy(col(\"count\").desc()) \\\n",
    "        .limit(Y)\n",
    "    return result.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_clubs_by_average_age(X, Y, highest=True):\n",
    "    if X <= 0:\n",
    "        return \"X must be a positive integer\"\n",
    "    if Y < 2015 or Y > 2022:\n",
    "        return \"Y must be a year between 2015 and 2022 inclusively\"\n",
    "    df = read_from_spark()\n",
    "    \n",
    "    # Filter data for specified year Y\n",
    "    df_filtered = df.filter(col(\"year\") == Y)\n",
    "    avg_age_per_club = df_filtered.groupBy(\"club_name\") \\\n",
    "        .agg(round(avg(\"age\").cast(\"float\"),2).alias(\"average_age\"))\n",
    "    if highest:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(desc(\"average_age\"))\n",
    "    else:\n",
    "        sorted_clubs = avg_age_per_club.orderBy(asc(\"average_age\"))\n",
    "\n",
    "    top_clubs = sorted_clubs.limit(X)\n",
    "    last_club = top_clubs.collect()[-1]\n",
    "    threshold_age = last_club[\"average_age\"]\n",
    "    if highest:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") >= threshold_age).collect()\n",
    "    else:\n",
    "        result_clubs = sorted_clubs.filter(col(\"average_age\") <= threshold_age).collect()\n",
    "    return result_clubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_popular_nationality():\n",
    "    df = read_from_spark()\n",
    "    # df_filtered = df.filter((col(\"year\") >= 2015) & (col(\"year\") <= 2022))\n",
    "    nationality_counts = df.groupBy(\"year\", \"nationality_name\") \\\n",
    "        .agg(count(\"*\").alias(\"count\"))\n",
    "    # Create a window partitioned by year and ordered by count descending\n",
    "    window = Window.partitionBy(\"year\").orderBy(desc(\"count\"))\n",
    "    \n",
    "    # Add row number within each year partition\n",
    "    ranked_nationalities = nationality_counts.withColumn(\"rank\", row_number().over(window))\n",
    "    # Filter for the top nationality for each year\n",
    "    most_popular_nationalities = ranked_nationalities.filter(col(\"rank\") == 1) \\\n",
    "        .select(\"year\", \"nationality_name\", \"count\") \\\n",
    "        .orderBy(\"year\")\n",
    "    \n",
    "    return most_popular_nationalities.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "top_clubs = get_top_clubs_with_contracts_ending(X=2021, Y=10, Z=2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='GwangJu FC', count=28),\n",
       " Row(club_name='Club Plaza de Deportes Colonia', count=27),\n",
       " Row(club_name='Zamora Fútbol Club', count=27),\n",
       " Row(club_name='Club Deportivo El Nacional', count=26),\n",
       " Row(club_name='SL Benfica', count=26),\n",
       " Row(club_name='Sociedad Deportiva Aucas', count=26),\n",
       " Row(club_name='Gangwon FC', count=26),\n",
       " Row(club_name='Busan IPark', count=26),\n",
       " Row(club_name='Club Atlético Nacional Potosí', count=26),\n",
       " Row(club_name='Club Olimpia', count=25)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_clubs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.2</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clubs_by_age = find_clubs_by_average_age(X=10, Y=2017, highest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(club_name='Sevilla Atlético', average_age=19.920000076293945),\n",
       " Row(club_name='Swindon Town', average_age=21.3700008392334),\n",
       " Row(club_name='CD Huachipato', average_age=21.40999984741211),\n",
       " Row(club_name='FC Nordsjælland', average_age=21.40999984741211),\n",
       " Row(club_name='FC Twente', average_age=21.59000015258789),\n",
       " Row(club_name='Envigado FC', average_age=21.610000610351562),\n",
       " Row(club_name='KRC Genk', average_age=21.6299991607666),\n",
       " Row(club_name='Crewe Alexandra', average_age=21.81999969482422),\n",
       " Row(club_name='Barnsley', average_age=21.8700008392334),\n",
       " Row(club_name='Ajax', average_age=21.969999313354492)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clubs_by_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Task-2.3</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "popular_nationalities = get_most_popular_nationality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year=2015, nationality_name='England', count=1627),\n",
       " Row(year=2016, nationality_name='England', count=1519),\n",
       " Row(year=2017, nationality_name='England', count=1627),\n",
       " Row(year=2018, nationality_name='England', count=1633),\n",
       " Row(year=2019, nationality_name='England', count=1625),\n",
       " Row(year=2020, nationality_name='England', count=1670),\n",
       " Row(year=2021, nationality_name='England', count=1685),\n",
       " Row(year=2022, nationality_name='England', count=1719)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popular_nationalities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "Refer to preprocessing.ipynb for detailed investigation on correlations and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setup column categories\n",
    "col_names = ['record_id',\n",
    " 'sofifa_id',\n",
    " 'player_url',\n",
    " 'short_name',\n",
    " 'long_name',\n",
    " 'player_positions',\n",
    " 'overall',\n",
    " 'potential',\n",
    " 'value_eur',\n",
    " 'wage_eur',\n",
    " 'age',\n",
    " 'dob',\n",
    " 'height_cm',\n",
    " 'weight_kg',\n",
    " 'club_team_id',\n",
    " 'club_name',\n",
    " 'league_name',\n",
    " 'league_level',\n",
    " 'club_position',\n",
    " 'club_jersey_number',\n",
    " 'club_loaned_from',\n",
    " 'club_joined',\n",
    " 'club_contract_valid_until',\n",
    " 'nationality_id',\n",
    " 'nationality_name',\n",
    " 'nation_team_id',\n",
    " 'nation_position',\n",
    " 'nation_jersey_number',\n",
    " 'preferred_foot',\n",
    " 'weak_foot',\n",
    " 'skill_moves',\n",
    " 'international_reputation',\n",
    " 'work_rate',\n",
    " 'body_type',\n",
    " 'real_face',\n",
    " 'release_clause_eur',\n",
    " 'player_tags',\n",
    " 'player_traits',\n",
    " 'pace',\n",
    " 'shooting',\n",
    " 'passing',\n",
    " 'dribbling',\n",
    " 'defending',\n",
    " 'physic',\n",
    " 'attacking_crossing',\n",
    " 'attacking_finishing',\n",
    " 'attacking_heading_accuracy',\n",
    " 'attacking_short_passing',\n",
    " 'attacking_volleys',\n",
    " 'skill_dribbling',\n",
    " 'skill_curve',\n",
    " 'skill_fk_accuracy',\n",
    " 'skill_long_passing',\n",
    " 'skill_ball_control',\n",
    " 'movement_acceleration',\n",
    " 'movement_sprint_speed',\n",
    " 'movement_agility',\n",
    " 'movement_reactions',\n",
    " 'movement_balance',\n",
    " 'power_shot_power',\n",
    " 'power_jumping',\n",
    " 'power_stamina',\n",
    " 'power_strength',\n",
    " 'power_long_shots',\n",
    " 'mentality_aggression',\n",
    " 'mentality_interceptions',\n",
    " 'mentality_positioning',\n",
    " 'mentality_vision',\n",
    " 'mentality_penalties',\n",
    " 'mentality_composure',\n",
    " 'defending_marking_awareness',\n",
    " 'defending_standing_tackle',\n",
    " 'defending_sliding_tackle',\n",
    " 'goalkeeping_diving',\n",
    " 'goalkeeping_handling',\n",
    " 'goalkeeping_kicking',\n",
    " 'goalkeeping_positioning',\n",
    " 'goalkeeping_reflexes',\n",
    " 'goalkeeping_speed',\n",
    " 'ls',\n",
    " 'st',\n",
    " 'rs',\n",
    " 'lw',\n",
    " 'lf',\n",
    " 'cf',\n",
    " 'rf',\n",
    " 'rw',\n",
    " 'lam',\n",
    " 'cam',\n",
    " 'ram',\n",
    " 'lm',\n",
    " 'lcm',\n",
    " 'cm',\n",
    " 'rcm',\n",
    " 'rm',\n",
    " 'lwb',\n",
    " 'ldm',\n",
    " 'cdm',\n",
    " 'rdm',\n",
    " 'rwb',\n",
    " 'lb',\n",
    " 'lcb',\n",
    " 'cb',\n",
    " 'rcb',\n",
    " 'rb',\n",
    " 'gk',\n",
    " 'player_face_url',\n",
    " 'club_logo_url',\n",
    " 'club_flag_url',\n",
    " 'nation_logo_url',\n",
    " 'nation_flag_url',\n",
    " 'year',\n",
    " 'gender']\n",
    "\n",
    "ordinal_cols = ['work_rate']\n",
    "nominal_cols = ['body_type']\n",
    "continuous_cols = ['potential', 'value_eur', 'wage_eur', 'age', 'height_cm', 'weight_kg',\n",
    "                   'weak_foot', 'skill_moves', 'international_reputation',\n",
    "                   'attacking_crossing','attacking_finishing', 'attacking_heading_accuracy', 'attacking_short_passing', 'attacking_volleys',\n",
    "                   'movement_sprint_speed', 'movement_agility', 'movement_reactions', 'movement_balance',\n",
    "                   'power_shot_power', 'power_jumping', 'power_stamina', 'power_strength', 'power_long_shots',\n",
    "                   'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties',\n",
    "                   'defending_marking_awareness', 'defending_standing_tackle', 'defending_sliding_tackle']\n",
    "\n",
    "main_traits_cols = ['pace', 'shooting', 'passing', 'dribbling', 'defending', 'physic', \n",
    "                            'goalkeeping_diving', 'goalkeeping_handling', 'goalkeeping_kicking',\n",
    "                            'goalkeeping_positioning', 'goalkeeping_reflexes', 'goalkeeping_speed']\n",
    "\n",
    "skill_cols = ['skill_dribbling', 'skill_curve', 'skill_fk_accuracy', 'skill_long_passing', 'skill_ball_control']\n",
    "\n",
    "position_cols = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw', 'lam', 'cam', 'ram', 'lm', 'lcm', 'cm',\n",
    "                   'rcm', 'rm', 'lwb', 'ldm', 'cdm', 'rdm', 'rwb', 'lb', 'lcb', 'cb', 'rcb', 'rb', 'gk']\n",
    "\n",
    "needed_cols = ['record_id', 'player_positions'] #needed for preprocessing but will be dropped\n",
    "\n",
    "columns_to_drop = ['sofifa_id', 'player_url', 'short_name', 'long_name',\n",
    "                   'dob', 'club_name', 'league_name', 'club_position', 'club_jersey_number', 'club_loaned_from',\n",
    "                   'club_joined','club_contract_valid_until', 'nationality_id', 'nationality_name', 'nation_team_id',\n",
    "                   'nation_position', 'nation_jersey_number', 'preferred_foot', 'real_face', 'player_tags', 'player_traits',\n",
    "                   'player_face_url', 'club_logo_url', 'club_flag_url', 'nation_logo_url', 'nation_flag_url',\n",
    "                   'year', 'gender', 'league_level']\n",
    "\n",
    "null_cols_drop = ['release_clause_eur']\n",
    "\n",
    "corr_cols_drop = ['movement_acceleration']\n",
    "\n",
    "dropped_null_rows = ['value_eur', 'wage_eur', 'trait6']\n",
    "\n",
    "imputed_cols = ['mentality_composure', 'club_team_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NullImputer(Transformer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset.withColumn(\"club_team_id_imputed\", when(col(\"club_team_id\").isNull(), -1).otherwise(col(\"club_team_id\")))\n",
    "        return output_df\n",
    "    \n",
    "class MLImputer(Transformer):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def _transform(self, dataset):\n",
    "        s = dataset.select(['record_id','mentality_composure', 'mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties']).toPandas()\n",
    "       \n",
    "        # Prepare the data\n",
    "        train_data = s.dropna(subset=['mentality_composure'])\n",
    "        X = train_data[['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties']]\n",
    "        Y = train_data['mentality_composure']\n",
    "\n",
    "        # Fit the linear regression model\n",
    "        model = LinearRegression()\n",
    "        model.fit(X, Y)\n",
    "\n",
    "        # Predict missing values\n",
    "        X_missing = s[s['mentality_composure'].isnull()][['mentality_aggression', 'mentality_interceptions', 'mentality_positioning', 'mentality_vision', 'mentality_penalties']]\n",
    "        predicted_values = model.predict(X_missing)\n",
    "        rounded_predicted_values = np.round(predicted_values).astype(int)\n",
    "        # Impute the predicted values\n",
    "        s.loc[s['mentality_composure'].isnull(), 'mentality_composure'] = rounded_predicted_values\n",
    "        s = s.rename(columns = {'mentality_composure': 'mentality_composure_imputed'})\n",
    "        spark_s = spark.createDataFrame(s[['record_id','mentality_composure_imputed']])\n",
    "        spark_df = dataset.join(spark_s, on = 'record_id', how = 'left')\n",
    "        return spark_df\n",
    "    \n",
    "class AverageSkillCreator(Transformer):\n",
    "    def __init__(self, average_skills_cols = None):\n",
    "        super().__init__()\n",
    "        self.average_skills_cols = average_skills_cols\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        spark_df = dataset\n",
    "        spark_df = spark_df.withColumn(\n",
    "        'corr_av_skills', \n",
    "        aggregate(\n",
    "            array(*[col(pos) for pos in self.average_skills_cols]),\n",
    "            lit(0.0),\n",
    "            lambda acc, x: acc + x,\n",
    "            lambda acc: acc / size(array(*[col(pos) for pos in self.average_skills_cols]))\n",
    "        )\n",
    "        )\n",
    "\n",
    "        return spark_df\n",
    "        \n",
    "class AveragePositionCreator(Transformer):\n",
    "    def __init__(self, position_cols = None):\n",
    "        super().__init__()\n",
    "        self.position_cols = position_cols\n",
    "\n",
    "    # Define UDF for safe evaluation\n",
    "    def safe_eval(self, x):\n",
    "        try:\n",
    "            return float(eval(str(x)))\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    def _transform(self, dataset):\n",
    "        attacking_positions = ['ls', 'st', 'rs', 'lw', 'lf', 'cf', 'rf', 'rw',\n",
    "                           'lam', 'cam', 'ram']\n",
    "        midfield_positions = ['lam', 'cam', 'ram', 'lm', 'lcm', 'cm', 'rcm', 'rm',\n",
    "                            'ldm', 'cdm', 'rdm']\n",
    "        defensive_positions = ['rwb', 'lb', 'lcb', 'cb', 'lwb', 'rcb', 'rb',\n",
    "                            'ldm', 'cdm', 'rdm']\n",
    "        gk_positions = ['gk']\n",
    "\n",
    "        spark_df = dataset\n",
    "        safe_eval_udf = udf(self.safe_eval, FloatType())\n",
    "\n",
    "        #Apply safe_eval to each position\n",
    "        for pos in position_cols:\n",
    "            spark_df = spark_df.withColumn(pos, safe_eval_udf(pos))\n",
    "\n",
    "         #Add new columns 'average_val_attacking', 'average_val_midfield', 'average_val_defensive', 'average_val_gk'\n",
    "        spark_df = spark_df.withColumn(\n",
    "            'average_val_attacking', \n",
    "            aggregate(\n",
    "                array(*[col(pos) for pos in attacking_positions]),\n",
    "                lit(0.0),\n",
    "                lambda acc, x: acc + x,\n",
    "                lambda acc: acc / size(array(*[col(pos) for pos in attacking_positions]))\n",
    "            )\n",
    "        )\n",
    "        spark_df = spark_df.withColumn(\n",
    "            'average_val_midfield', \n",
    "            aggregate(\n",
    "                array(*[col(pos) for pos in midfield_positions]),\n",
    "                lit(0.0),\n",
    "                lambda acc, x: acc + x,\n",
    "                lambda acc: acc / size(array(*[col(pos) for pos in midfield_positions]))\n",
    "            )\n",
    "        )\n",
    "        spark_df = spark_df.withColumn(\n",
    "            'average_val_defensive', \n",
    "            aggregate(\n",
    "                array(*[col(pos) for pos in defensive_positions]),\n",
    "                lit(0.0),\n",
    "                lambda acc, x: acc + x,\n",
    "                lambda acc: acc / size(array(*[col(pos) for pos in defensive_positions]))\n",
    "            )\n",
    "        )\n",
    "        spark_df = spark_df.withColumn(\n",
    "            'average_val_gk', \n",
    "            aggregate(\n",
    "                array(*[col(pos) for pos in gk_positions]),\n",
    "                lit(0.0),\n",
    "                lambda acc, x: acc + x,\n",
    "                lambda acc: acc / size(array(*[col(pos) for pos in gk_positions]))\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return spark_df\n",
    "\n",
    "def assign_traits(player_positions, *traits):\n",
    "        #Trait1 = pace/goalkeeping_diving\n",
    "        #Trait2 = shooting/goalkeeping_handling\n",
    "        #Trait3 = passing/goalkeeping_kicking\n",
    "        #Trait4 = dribbling/goalkeeping_positioning\n",
    "        #Trait5 = defending/goalkeeping_reflexes\n",
    "        #Trait6 = physic/goalkeeping_speed\n",
    "\n",
    "        traits = [float(t) if t is not None else None for t in traits]\n",
    "        if player_positions and 'GK' in player_positions:\n",
    "            return traits[6:12]\n",
    "        else:\n",
    "            return traits[:6]\n",
    "\n",
    "class MergeMainTraits(Transformer):\n",
    "    def __init__(self, main_traits_cols = None):\n",
    "        super().__init__()\n",
    "        self.main_traits_cols = main_traits_cols\n",
    "        \n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        assign_traits_udf = udf(assign_traits, ArrayType(FloatType()))\n",
    "        output_df = output_df.withColumn('traits', \n",
    "                                       assign_traits_udf(col('player_positions'), *[col(trait) for trait in self.main_traits_cols]))\n",
    "        for i in range(1, 7):\n",
    "            output_df = output_df.withColumn(f'trait{i}', col('traits').getItem(i-1))\n",
    "        \n",
    "        output_df = output_df.drop('traits')\n",
    "        return output_df\n",
    "    \n",
    "class DropOutliers(Transformer):\n",
    "    def __init__(self, continuous_cols = None):\n",
    "        super().__init__()\n",
    "        self.continuous_cols = continuous_cols\n",
    "\n",
    "    def column_add(self, a,b):\n",
    "        return  a.__add__(b)\n",
    "    \n",
    "    def find_outliers(self, df, continuous_cols):\n",
    "        # Identifying the numerical columns in a spark dataframe\n",
    "\n",
    "        # Using the `for` loop to create new columns by identifying the outliers for each feature\n",
    "        for column in continuous_cols:\n",
    "\n",
    "            less_Q1 = 'less_Q1_{}'.format(column)\n",
    "            more_Q3 = 'more_Q3_{}'.format(column)\n",
    "            Q1 = 'Q1_{}'.format(column)\n",
    "            Q3 = 'Q3_{}'.format(column)\n",
    "\n",
    "            # Q1 : First Quartile ., Q3 : Third Quartile\n",
    "            Q1 = df.approxQuantile(column,[0.25],relativeError=0)\n",
    "            Q3 = df.approxQuantile(column,[0.75],relativeError=0)\n",
    "            \n",
    "            # IQR : Inter Quantile Range\n",
    "            # We need to define the index [0], as Q1 & Q3 are a set of lists., to perform a mathematical operation\n",
    "            # Q1 & Q3 are defined seperately so as to have a clear indication on First Quantile & 3rd Quantile\n",
    "            IQR = Q3[0] - Q1[0]\n",
    "            \n",
    "            #selecting the data, with -1.5*IQR to + 1.5*IQR., where param = 1.5 default value\n",
    "            less_Q1 =  Q1[0] - 1.5*IQR\n",
    "            more_Q3 =  Q3[0] + 1.5*IQR\n",
    "            \n",
    "            isOutlierCol = 'is_outlier_{}'.format(column)\n",
    "            \n",
    "            df = df.withColumn(isOutlierCol,when((df[column] > more_Q3) | (df[column] < less_Q1), 1).otherwise(0))\n",
    "        \n",
    "\n",
    "        # Selecting the specific columns which we have added above, to check if there are any outliers\n",
    "        selected_columns = [column for column in df.columns if column.startswith(\"is_outlier\")]\n",
    "        # Adding all the outlier columns into a new colum \"total_outliers\", to see the total number of outliers\n",
    "        df = df.withColumn('total_outliers',reduce(self.column_add, ( df[col] for col in  selected_columns)))\n",
    "\n",
    "        # Dropping the extra columns created above, just to create nice dataframe., without extra columns\n",
    "        df = df.drop(*[column for column in df.columns if column.startswith(\"is_outlier\")])\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        df_outliers = self.find_outliers(dataset, continuous_cols)\n",
    "        df_no_outliers = df_outliers.filter(df_outliers['total_outliers']<=6) #Drop all rows with more than 6 outliers\n",
    "        df_no_outliers = df_no_outliers.drop(\"total_outliers\")\n",
    "        return df_no_outliers    \n",
    "     \n",
    "class DropNullRows(Transformer):\n",
    "    def __init__(self, dropped_null_rows = None):\n",
    "        super().__init__()\n",
    "        self.null_cols_drop = dropped_null_rows\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset.na.drop(subset=self.null_cols_drop)\n",
    "        return output_df\n",
    "\n",
    "class FeatureTypeCaster(Transformer): # this transformer will cast the columns as appropriate types  \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in (continuous_cols + imputed_cols):\n",
    "            output_df = output_df.withColumn(col_name,col(col_name).cast(DoubleType()))\n",
    "        return output_df\n",
    "    \n",
    "class ColumnDropper(Transformer): # this transformer drops unnecessary columns\n",
    "    def __init__(self, columns_to_drop = None):\n",
    "        super().__init__()\n",
    "        self.columns_to_drop=columns_to_drop\n",
    "    def _transform(self, dataset):\n",
    "        output_df = dataset\n",
    "        for col_name in self.columns_to_drop:\n",
    "            output_df = output_df.drop(col_name)\n",
    "        return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessing_pipeline():\n",
    "    #Drop all initial columns that are not needed\n",
    "    stage_dropper = ColumnDropper(columns_to_drop = columns_to_drop + null_cols_drop + corr_cols_drop)\n",
    "\n",
    "    # Stage where columns are casted as appropriate types\n",
    "    stage_typecaster = FeatureTypeCaster()\n",
    "\n",
    "    #Engineer features\n",
    "    stage_maintraits = MergeMainTraits(main_traits_cols)\n",
    "    trait_cols = ['trait1', 'trait2', 'trait3', 'trait4', 'trait5', 'trait6']\n",
    "\n",
    "    stage_average_positions = AveragePositionCreator(position_cols)\n",
    "    avg_position_cols = ['average_val_attacking', 'average_val_midfield', 'average_val_defensive', 'average_val_gk']\n",
    "   \n",
    "    stage_average_skills = AverageSkillCreator(skill_cols)\n",
    "    avg_skill_cols = [\"corr_av_skills\"]\n",
    "\n",
    "    #Impute features\n",
    "    imputed_id_cols = [x+\"_imputed\" for x in imputed_cols]\n",
    "    stage_imputer = NullImputer()\n",
    "    stage_ml_imputer = MLImputer()\n",
    "    \n",
    "    #Stage where null rows are dropped based on certain features\n",
    "    stage_null_dropper = DropNullRows(dropped_null_rows)\n",
    "\n",
    "    #Stage where outlier rows are dropped for continuous features\n",
    "    stage_outlier_dropper = DropOutliers(continuous_cols)\n",
    "\n",
    "    # Stage where nominal columns are transformed to index columns using StringIndexer\n",
    "    nominal_id_cols = [x+\"_index\" for x in nominal_cols]\n",
    "    nominal_onehot_cols = [x+\"_encoded\" for x in nominal_cols]\n",
    "    stage_nominal_indexer = StringIndexer(inputCols = nominal_cols, outputCols = nominal_id_cols )\n",
    "\n",
    "    # Stage where the index columns are further transformed using OneHotEncoder\n",
    "    stage_nominal_onehot_encoder = OneHotEncoder(inputCols=nominal_id_cols, outputCols=nominal_onehot_cols)\n",
    "\n",
    "    # Stage where ordinal columns are transformed to index columns using StringIndexer\n",
    "    ordinal_id_cols = [x+\"_index\" for x in ordinal_cols]\n",
    "    stage_ordinal_indexer = StringIndexer(inputCols = ordinal_cols, outputCols = ordinal_id_cols )\n",
    "\n",
    "    # Stage where all relevant features are assembled into a vector (and dropping a few)\n",
    "    feature_cols = continuous_cols + nominal_onehot_cols + ordinal_id_cols + trait_cols + avg_position_cols + avg_skill_cols + imputed_id_cols #[imputed_id_cols[1]]\n",
    "    stage_vector_assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"vectorized_features\")\n",
    "\n",
    "    # Stage where we scale the columns\n",
    "    stage_scaler = StandardScaler(inputCol= 'vectorized_features', outputCol= 'features')\n",
    "    \n",
    "    # Removing all unnecessary columbs, only keeping the 'features' and 'outcome' columns\n",
    "    stage_column_dropper = ColumnDropper(columns_to_drop = feature_cols + main_traits_cols + \n",
    "                                         position_cols + skill_cols + imputed_cols + needed_cols + ordinal_cols + nominal_cols + nominal_id_cols +['vectorized_features'])\n",
    "    \n",
    "    # Connect the columns into a pipeline\n",
    "    pipeline = Pipeline(stages=[stage_dropper, stage_typecaster, stage_maintraits, stage_average_positions, stage_average_skills,\n",
    "                                stage_imputer, stage_ml_imputer, stage_null_dropper, stage_nominal_indexer, stage_nominal_onehot_encoder, stage_ordinal_indexer,\n",
    "                                stage_vector_assembler, stage_scaler, stage_column_dropper])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_from_spark()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/14 18:24:46 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "[Stage 71:====================================================>   (34 + 2) / 36]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|overall|            features|\n",
      "+-------+--------------------+\n",
      "|     78|[12.4282380864398...|\n",
      "|     75|[11.9502289292691...|\n",
      "|     67|[10.6755378434804...|\n",
      "|     83|[13.2249200150578...|\n",
      "|     78|[12.4282380864398...|\n",
      "|     77|[12.2689017007163...|\n",
      "|     77|[12.2689017007163...|\n",
      "|     74|[11.7908925435455...|\n",
      "|     70|[12.1095653149927...|\n",
      "|     69|[10.9942106149276...|\n",
      "|     67|[10.6755378434804...|\n",
      "|     66|[10.5162014577568...|\n",
      "|     72|[11.4722197720983...|\n",
      "|     71|[11.3128833863747...|\n",
      "|     69|[10.9942106149276...|\n",
      "|     80|[13.3842564007814...|\n",
      "|     74|[11.7908925435455...|\n",
      "|     74|[13.2249200150578...|\n",
      "|     69|[11.1535470006511...|\n",
      "|     74|[11.7908925435455...|\n",
      "+-------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipeline = get_preprocessing_pipeline()\n",
    "preprocess_model = pipeline.fit(df)\n",
    "df_clean = preprocess_model.transform(df)\n",
    "df_clean.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean.withColumn('overall', col('overall').cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SparkML</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression as spark_LR, DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#80/20 split into Train and Test\n",
    "train_data, test_data = df_clean.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ML_pipeline(ML_model):\n",
    "    if ML_model == \"LR\":\n",
    "        ml = spark_LR(featuresCol='features', labelCol='overall')\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(ml.regParam, [0.01, 0.5, 2.0])\n",
    "                .addGrid(ml.maxIter, [1, 5, 10])\n",
    "                .build())\n",
    "        \n",
    "    elif ML_model == \"DT\":\n",
    "        ml = DecisionTreeRegressor(featuresCol='features', labelCol='overall')\n",
    "\n",
    "        paramGrid = (ParamGridBuilder()\n",
    "                .addGrid(ml.minInfoGain, [0.0, 0.1, 0.2])\n",
    "                .addGrid(ml.minInstancesPerNode, [1, 2])\n",
    "                .build())\n",
    "    \n",
    "    evaluator = RegressionEvaluator(predictionCol='prediction', \n",
    "            labelCol='overall', metricName='r2')\n",
    "    \n",
    "    stage_ML = CrossValidator(estimator=ml, estimatorParamMaps=paramGrid, \n",
    "                           evaluator=evaluator, numFolds=5)\n",
    "    \n",
    "#     pipeline = Pipeline(stages=[stage_ML])\n",
    "    pipeline = Pipeline(stages=[ml])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/14 18:25:52 WARN Instrumentation: [8adafc5a] regParam is zero, which might cause numerical instability and overfitting.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR train r2 score: 93.59%\n",
      "LR test r2 score: 93.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 147:=====================================>                 (11 + 5) / 16]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT train r2 score: 92.94%\n",
      "DT test r2 score: 92.93%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r                                                                                \r"
     ]
    }
   ],
   "source": [
    "ML_model = [\"LR\", \"DT\"]\n",
    "\n",
    "evaluator = RegressionEvaluator(predictionCol='prediction', \n",
    "            labelCol='overall', metricName='r2')\n",
    "\n",
    "for model in ML_model:\n",
    "    ML_pipeline = get_ML_pipeline(model)\n",
    "    ML_model_pipeline = ML_pipeline.fit(train_data) #training\n",
    "    model_df_train = ML_model_pipeline.transform(train_data) #train predictions\n",
    "    model_df_test = ML_model_pipeline.transform(test_data)  #test predictions\n",
    "\n",
    "    r2_train = evaluator.evaluate(model_df_train)\n",
    "    r2_test = evaluator.evaluate(model_df_test)\n",
    "    print(f\"{model} train r2 score: {r2_train}\")\n",
    "    print(f\"{model} test r2 score: {r2_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pytorch</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "s = df_clean.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Check if MPS is available\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target\n",
    "X = s.drop('overall', axis=1)\n",
    "y = s['overall']\n",
    "# Split the data into train+validation and test sets\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "# Further split train+validation into train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.from_numpy(np.array(X_train['features'].values.tolist(), np.float32))\n",
    "X_val = torch.from_numpy(np.array(X_val['features'].values.tolist(), np.float32))\n",
    "X_test = torch.from_numpy(np.array(X_test['features'].values.tolist(), np.float32))\n",
    "y_train = torch.from_numpy(np.array(y_train, np.float32))\n",
    "y_val = torch.from_numpy(np.array(y_val, np.float32))\n",
    "y_test = torch.from_numpy(np.array(y_test, np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train).to(device)\n",
    "y_train_tensor = torch.FloatTensor(y_train).reshape(-1, 1).to(device)\n",
    "X_val_tensor = torch.FloatTensor(X_val).to(device)\n",
    "y_val_tensor = torch.FloatTensor(y_val).reshape(-1, 1).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test).to(device)\n",
    "y_test_tensor = torch.FloatTensor(y_test).reshape(-1, 1).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: Multi-layer Perceptron (MLP)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear = nn.Linear(input_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100):\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_true = []\n",
    "        train_pred = []\n",
    "        \n",
    "        for inputs, targets in train_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            train_true.extend(targets.cpu().numpy())\n",
    "            train_pred.extend(outputs.detach().cpu().numpy())\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_true = []\n",
    "        val_pred = []\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                val_loss += criterion(outputs, targets).item()\n",
    "                \n",
    "                val_true.extend(targets.cpu().numpy())\n",
    "                val_pred.extend(outputs.cpu().numpy())\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        val_loss /= len(val_loader)\n",
    "        \n",
    "        train_r2 = r2_score(train_true, train_pred)\n",
    "        val_r2 = r2_score(val_true, val_pred)\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "                  f'Train Loss: {train_loss:.4f}, Train R2: {train_r2:.4f}, '\n",
    "                  f'Val Loss: {val_loss:.4f}, Val R2: {val_r2:.4f}')\n",
    "    \n",
    "    return val_loss, val_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparameters(model_class, param_grid):\n",
    "    best_val_loss = float('inf')\n",
    "    best_params = None\n",
    "    best_model = None\n",
    "    best_val_r2 = -float('inf')\n",
    "\n",
    "    for params in product(*param_grid.values()):\n",
    "        current_params = dict(zip(param_grid.keys(), params))\n",
    "        print(f\"Training with parameters: {current_params}\")\n",
    "\n",
    "        if model_class == MLP:\n",
    "            model = model_class(input_size=X_train.shape[1], hidden_size=current_params['hidden_size'])\n",
    "        elif model_class == LinearRegression:\n",
    "            model = model_class(input_size=X_train.shape[1])\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported model class\")\n",
    "\n",
    "        optimizer = optim.Adam(model.parameters(), lr=current_params['lr'])\n",
    "        criterion = nn.MSELoss()\n",
    "        train_loader = DataLoader(train_dataset, batch_size=current_params['batch_size'], shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=current_params['batch_size'])\n",
    "\n",
    "        val_loss, val_r2 = train_model(model, train_loader, val_loader, criterion, optimizer)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_r2 = val_r2\n",
    "            best_val_loss = val_loss\n",
    "            best_params = current_params\n",
    "            best_model = model.state_dict()\n",
    "\n",
    "    return best_params, best_val_loss, best_model, best_val_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_function(model_class):\n",
    "    input_size = X_test_tensor.shape[1]\n",
    "    if model_class == \"LR\":\n",
    "        model = LinearRegression(input_size)\n",
    "        model.load_state_dict(torch.load('./best_linear_model.pth'))\n",
    "    elif model_class == \"MLP\":\n",
    "        model = MLP(input_size, mlp_best_params['hidden_size'])\n",
    "        model.load_state_dict(torch.load('./best_mlp_model.pth'))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X_test_tensor)\n",
    "    y_pred_np = y_pred.cpu().numpy()\n",
    "    y_test_np = y_test_tensor.cpu().numpy()\n",
    "    \n",
    "    r2 = r2_score(y_test_np, y_pred_np)\n",
    "    mse = mean_squared_error(y_test_np, y_pred_np)\n",
    "    rmse = np.sqrt(mse)\n",
    "    \n",
    "    print(f\"R2 Score: {r2:.4f}\")\n",
    "    print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hyperparameter grids\n",
    "mlp_param_grid = {\n",
    "    'lr': [0.01],\n",
    "    'batch_size': [32],\n",
    "    'hidden_size': [32]\n",
    "}\n",
    "# mlp_param_grid = {\n",
    "#     'lr': [0.001, 0.01],\n",
    "#     'batch_size': [32, 64],\n",
    "#     'hidden_size': [32, 64]\n",
    "# }\n",
    "linear_param_grid = {\n",
    "    'lr': [0.01],\n",
    "    'batch_size': [32]\n",
    "}\n",
    "# linear_param_grid = {\n",
    "#     'lr': [0.001, 0.01],\n",
    "#     'batch_size': [32, 64]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning MLP model...\n",
      "Training with parameters: {'lr': 0.01, 'batch_size': 32, 'hidden_size': 32}\n",
      "Epoch [10/100], Train Loss: 1.2122, Train R2: 0.9758, Val Loss: 1.5523, Val R2: 0.9686\n",
      "Epoch [20/100], Train Loss: 1.1042, Train R2: 0.9780, Val Loss: 0.8979, Val R2: 0.9818\n",
      "Epoch [30/100], Train Loss: 1.0307, Train R2: 0.9794, Val Loss: 0.9923, Val R2: 0.9799\n",
      "Epoch [40/100], Train Loss: 1.0304, Train R2: 0.9794, Val Loss: 1.0523, Val R2: 0.9787\n",
      "Epoch [50/100], Train Loss: 1.0027, Train R2: 0.9800, Val Loss: 2.1456, Val R2: 0.9565\n",
      "Epoch [60/100], Train Loss: 1.0127, Train R2: 0.9798, Val Loss: 0.8713, Val R2: 0.9824\n",
      "Epoch [70/100], Train Loss: 0.9985, Train R2: 0.9801, Val Loss: 0.8447, Val R2: 0.9829\n",
      "Epoch [80/100], Train Loss: 0.9970, Train R2: 0.9801, Val Loss: 1.3344, Val R2: 0.9730\n",
      "Epoch [90/100], Train Loss: 0.9951, Train R2: 0.9801, Val Loss: 0.9563, Val R2: 0.9806\n",
      "Epoch [100/100], Train Loss: 0.9877, Train R2: 0.9803, Val Loss: 0.8447, Val R2: 0.9829\n",
      "Best MLP parameters: {'lr': 0.01, 'batch_size': 32, 'hidden_size': 32}\n",
      "Best MLP validation loss: 0.8447141112937737\n",
      "Best MLP validation r2: 0.9828898670092397\n"
     ]
    }
   ],
   "source": [
    "# Tune and train models\n",
    "print(\"Tuning MLP model...\")\n",
    "mlp_best_params, mlp_best_loss, mlp_best_model, mlp_best_r2 = tune_hyperparameters(MLP, mlp_param_grid)\n",
    "print(f\"Best MLP parameters: {mlp_best_params}\")\n",
    "print(f\"Best MLP validation loss: {mlp_best_loss}\")\n",
    "print(f\"Best MLP validation r2: {mlp_best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuning Linear Regression model...\n",
      "Training with parameters: {'lr': 0.01, 'batch_size': 32}\n",
      "Epoch [10/100], Train Loss: 3.4635, Train R2: 0.9309, Val Loss: 3.2733, Val R2: 0.9337\n",
      "Epoch [20/100], Train Loss: 3.4843, Train R2: 0.9304, Val Loss: 3.4548, Val R2: 0.9300\n",
      "Epoch [30/100], Train Loss: 3.4760, Train R2: 0.9306, Val Loss: 3.5064, Val R2: 0.9290\n",
      "Epoch [40/100], Train Loss: 3.4533, Train R2: 0.9311, Val Loss: 3.2148, Val R2: 0.9349\n",
      "Epoch [50/100], Train Loss: 3.4465, Train R2: 0.9312, Val Loss: 3.3926, Val R2: 0.9313\n",
      "Epoch [60/100], Train Loss: 3.4505, Train R2: 0.9311, Val Loss: 3.4550, Val R2: 0.9300\n",
      "Epoch [70/100], Train Loss: 3.4430, Train R2: 0.9313, Val Loss: 4.4850, Val R2: 0.9092\n",
      "Epoch [80/100], Train Loss: 3.4513, Train R2: 0.9311, Val Loss: 3.2899, Val R2: 0.9334\n",
      "Epoch [90/100], Train Loss: 3.4527, Train R2: 0.9311, Val Loss: 3.3014, Val R2: 0.9331\n",
      "Epoch [100/100], Train Loss: 3.4591, Train R2: 0.9309, Val Loss: 3.4960, Val R2: 0.9292\n",
      "Best Linear Regression parameters: {'lr': 0.01, 'batch_size': 32}\n",
      "Best Linear Regression validation loss: 3.4959638535381212\n",
      "Best Linear Regression validation R2: 0.9291859566771667\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTuning Linear Regression model...\")\n",
    "linear_best_params, linear_best_loss, linear_best_model, linear_best_r2 = tune_hyperparameters(LinearRegression, linear_param_grid)\n",
    "print(f\"Best Linear Regression parameters: {linear_best_params}\")\n",
    "print(f\"Best Linear Regression validation loss: {linear_best_loss}\")\n",
    "print(f\"Best Linear Regression validation R2: {linear_best_r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best models\n",
    "torch.save(mlp_best_model, 'best_mlp_model.pth')\n",
    "torch.save(linear_best_model, 'best_linear_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9831\n",
      "Mean Squared Error: 0.8542\n",
      "Root Mean Squared Error: 0.9242\n"
     ]
    }
   ],
   "source": [
    "test_function(\"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.9289\n",
      "Mean Squared Error: 3.5936\n",
      "Root Mean Squared Error: 1.8957\n"
     ]
    }
   ],
   "source": [
    "test_function(\"LR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
